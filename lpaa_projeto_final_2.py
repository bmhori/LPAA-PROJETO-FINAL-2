# -*- coding: utf-8 -*-
"""LPAA PROJETO FINAL 2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1czoo2Toowb_IljUtuHPtedW03CPZuONx
"""

!git clone https://github.com/bmhori/LPAA-PROJETO-FINAL-2.git

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Carregar os dados
dados = pd.read_csv('/content/LPAA-PROJETO-FINAL-2/DiseaseAndSymptoms.csv')

# Visualizar as primeiras linhas dos dados
print(dados.head())

# Verificar as informações básicas dos dados
print(dados.info())

# Estatísticas descritivas dos dados
print(dados.describe())

# Verificar valores ausentes nos dados
print(dados.isnull().sum())

# Carregar o conjunto de dados
df = pd.read_csv("/content/LPAA-PROJETO-FINAL-2/DiseaseAndSymptoms.csv")

# Extrair nomes dos sintomas
sintomas = df.columns[1:]
sintomas = [coluna.split("_")[1].capitalize() for coluna in sintomas]
# Extrair nomes dos sintomas
sintomas_unicos = df.iloc[:, 1:].stack().str.split('_').str[-1].str.capitalize().unique()





print(sintomas_unicos)

sintomas = sintomas_unicos

# Converter a lista para uma série do pandas
serie_sintomas = pd.Series(sintomas)

# Contar a ocorrência de cada sintoma
contagem_sintomas = serie_sintomas.value_counts()

print(contagem_sintomas)

sintomas = dados.iloc[:, 1:].melt()['value'].value_counts()

# Selecionar os 10 principais sintomas
top_10_sintomas = sintomas.head(10)

plt.figure(figsize=(12, 6))
sns.barplot(x=top_10_sintomas.values, y=top_10_sintomas.index, palette='viridis')
plt.title('Top 10 Sintomas Mais Comuns')
plt.xlabel('Número de Casos')
plt.ylabel('Sintoma')
plt.show()

# Contagem de ocorrências de doenças
top_10_doencas = dados['Disease'].value_counts().head(10)

# Visualização das 10 principais doenças
plt.figure(figsize=(10, 6))
sns.barplot(x=top_10_doencas.values, y=top_10_doencas.index, palette='viridis')
plt.title('Top 10 Doenças Mais Comuns')
plt.xlabel('Número de Casos')
plt.ylabel('Doença')
plt.show()

# Preencher valores ausentes com um valor padrão (por exemplo, 'desconhecido')
dados.fillna('desconhecido', inplace=True)

# Remover duplicatas
dados.drop_duplicates(inplace=True)

dados = dados.apply(lambda x: x.str.strip() if x.dtype == "object" else x)
dados = dados.apply(lambda x: x.str.lower() if x.dtype == "object" else x)
dados.columns = dados.columns.str.replace(' ', '_').str.lower()

for column in dados.columns:
    unique_values = dados[column].unique()
    #print(f"Valores únicos em {column}: {unique_values}")

from sklearn.preprocessing import StandardScaler

# Criar variáveis dummy para todas as colunas de sintomas
dados_encoded = pd.get_dummies(dados, columns=['symptom_1', 'symptom_2', 'symptom_3', 'symptom_4',
                                              'symptom_5', 'symptom_6', 'symptom_7', 'symptom_8',
                                              'symptom_9', 'symptom_10', 'symptom_11', 'symptom_12',
                                              'symptom_13', 'symptom_14', 'symptom_15', 'symptom_16',
                                              'symptom_17'])

# Separe os recursos (X) e os rótulos (y)
X = dados_encoded.drop('disease', axis=1)
y = dados_encoded['disease']

# Normalizar os recursos
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, accuracy_score

# Dividir os dados em conjuntos de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Inicializar e treinar o modelo de Árvore de Decisão
decision_tree = DecisionTreeClassifier(random_state=42)
decision_tree.fit(X_train, y_train)

# Fazer previsões
y_pred = decision_tree.predict(X_test)

# Avaliar o desempenho do modelo
accuracy = accuracy_score(y_test, y_pred)
print("Acurácia do Modelo de Árvore de Decisão:", accuracy)
print("\nRelatório de Classificação:")
print(classification_report(y_test, y_pred))

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Dividir os dados em conjuntos de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Inicializar e treinar o modelo de Random Forest
random_forest = RandomForestClassifier(random_state=42)
random_forest.fit(X_train, y_train)

# Fazer previsões
y_pred = random_forest.predict(X_test)

# Avaliar o desempenho do modelo
accuracy = accuracy_score(y_test, y_pred)
print("Acurácia do Modelo de Random Forest:", accuracy)

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Dividir os dados em conjuntos de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Inicializar e treinar o modelo KNN
knn = KNeighborsClassifier()
knn.fit(X_train, y_train)

# Fazer previsões
y_pred = knn.predict(X_test)

# Avaliar o desempenho do modelo
accuracy = accuracy_score(y_test, y_pred)
print("Acurácia do Modelo KNN:", accuracy)

from sklearn.model_selection import GridSearchCV

# Definir os hiperparâmetros que você deseja testar
param_grid = {
    'criterion': ['gini', 'entropy'],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['auto', 'sqrt', 'log2']
}

# Inicializar o modelo de Árvore de Decisão
decision_tree = DecisionTreeClassifier(random_state=42)

# Inicializar o objeto GridSearchCV
grid_search = GridSearchCV(estimator=decision_tree, param_grid=param_grid, cv=5, scoring='accuracy')

# Realizar a busca de grade
grid_search.fit(X_train, y_train)

# Exibir os melhores hiperparâmetros encontrados
#print("Melhores Hiperparâmetros Encontrados:")
#print(grid_search.best_params_)

# Obter o melhor modelo encontrado
best_decision_tree = grid_search.best_estimator_

# Fazer previsões com o melhor modelo
y_pred = best_decision_tree.predict(X_test)

# Avaliar o desempenho do modelo
accuracy = accuracy_score(y_test, y_pred)
print("Acurácia do Modelo de Árvore de Decisão com Melhores Hiperparâmetros:", accuracy)
#print("\nRelatório de Classificação:")
#print(classification_report(y_test, y_pred))

from sklearn.preprocessing import StandardScaler

# Sintomas fornecidos pelo paciente
sintomas_paciente = ['acidity indigestion', 'blurred_and_distorted_vision', 'excessive_hunger', 'stiff_neck']

# Criar um DataFrame com os sintomas do paciente
dados_paciente = pd.DataFrame(columns=dados_encoded.columns[1:])
dados_paciente.loc[0] = 0  # Inicializar todos os sintomas como 0

# Marcar como 1 os sintomas presentes no paciente
for sintoma in sintomas_paciente:
    for coluna in dados_paciente.columns:
        if 'symptom_' + sintoma.lower().replace(' ', '_') in coluna:
            dados_paciente.loc[0, coluna] = 1

# Escalar os sintomas do paciente
scaler = StandardScaler()
X_patient_scaled = scaler.fit_transform(dados_paciente)

# Fazer a previsão usando o modelo treinado
doenca_prevista = best_decision_tree.predict(X_patient_scaled)

# Exibir a doença prevista
print("Doença prevista:", doenca_prevista)